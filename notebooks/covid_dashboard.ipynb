{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6193cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2951f2",
   "metadata": {},
   "source": [
    "### 1. update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ef8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "raw_data = pd.read_csv(data_url, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f9cdfef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>female_smokers</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0      AFG      Asia  Afghanistan  2020-02-24          5.0        5.0   \n",
       "1      AFG      Asia  Afghanistan  2020-02-25          5.0        0.0   \n",
       "2      AFG      Asia  Afghanistan  2020-02-26          5.0        0.0   \n",
       "3      AFG      Asia  Afghanistan  2020-02-27          5.0        0.0   \n",
       "4      AFG      Asia  Afghanistan  2020-02-28          5.0        0.0   \n",
       "\n",
       "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
       "0                 NaN           NaN         NaN                  NaN  ...   \n",
       "1                 NaN           NaN         NaN                  NaN  ...   \n",
       "2                 NaN           NaN         NaN                  NaN  ...   \n",
       "3                 NaN           NaN         NaN                  NaN  ...   \n",
       "4                 NaN           NaN         NaN                  NaN  ...   \n",
       "\n",
       "   female_smokers  male_smokers  handwashing_facilities  \\\n",
       "0             NaN           NaN                  37.746   \n",
       "1             NaN           NaN                  37.746   \n",
       "2             NaN           NaN                  37.746   \n",
       "3             NaN           NaN                  37.746   \n",
       "4             NaN           NaN                  37.746   \n",
       "\n",
       "   hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
       "0                         0.5            64.83                    0.511   \n",
       "1                         0.5            64.83                    0.511   \n",
       "2                         0.5            64.83                    0.511   \n",
       "3                         0.5            64.83                    0.511   \n",
       "4                         0.5            64.83                    0.511   \n",
       "\n",
       "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                   NaN                          NaN   \n",
       "1                                   NaN                          NaN   \n",
       "2                                   NaN                          NaN   \n",
       "3                                   NaN                          NaN   \n",
       "4                                   NaN                          NaN   \n",
       "\n",
       "   excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0               NaN                                      NaN  \n",
       "1               NaN                                      NaN  \n",
       "2               NaN                                      NaN  \n",
       "3               NaN                                      NaN  \n",
       "4               NaN                                      NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a28d4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iso_code', 'continent', 'location', 'date', 'total_cases', 'new_cases',\n",
       "       'new_cases_smoothed', 'total_deaths', 'new_deaths',\n",
       "       'new_deaths_smoothed', 'total_cases_per_million',\n",
       "       'new_cases_per_million', 'new_cases_smoothed_per_million',\n",
       "       'total_deaths_per_million', 'new_deaths_per_million',\n",
       "       'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients',\n",
       "       'icu_patients_per_million', 'hosp_patients',\n",
       "       'hosp_patients_per_million', 'weekly_icu_admissions',\n",
       "       'weekly_icu_admissions_per_million', 'weekly_hosp_admissions',\n",
       "       'weekly_hosp_admissions_per_million', 'total_tests', 'new_tests',\n",
       "       'total_tests_per_thousand', 'new_tests_per_thousand',\n",
       "       'new_tests_smoothed', 'new_tests_smoothed_per_thousand',\n",
       "       'positive_rate', 'tests_per_case', 'tests_units', 'total_vaccinations',\n",
       "       'people_vaccinated', 'people_fully_vaccinated', 'total_boosters',\n",
       "       'new_vaccinations', 'new_vaccinations_smoothed',\n",
       "       'total_vaccinations_per_hundred', 'people_vaccinated_per_hundred',\n",
       "       'people_fully_vaccinated_per_hundred', 'total_boosters_per_hundred',\n",
       "       'new_vaccinations_smoothed_per_million',\n",
       "       'new_people_vaccinated_smoothed',\n",
       "       'new_people_vaccinated_smoothed_per_hundred', 'stringency_index',\n",
       "       'population', 'population_density', 'median_age', 'aged_65_older',\n",
       "       'aged_70_older', 'gdp_per_capita', 'extreme_poverty',\n",
       "       'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers',\n",
       "       'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand',\n",
       "       'life_expectancy', 'human_development_index',\n",
       "       'excess_mortality_cumulative_absolute', 'excess_mortality_cumulative',\n",
       "       'excess_mortality', 'excess_mortality_cumulative_per_million'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87261265",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = raw_data.loc[:, [\"date\", \"location\", \"total_cases\", \"people_vaccinated\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34b16889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>people_vaccinated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     location  total_cases  people_vaccinated\n",
       "0  2020-02-24  Afghanistan          5.0                NaN\n",
       "1  2020-02-25  Afghanistan          5.0                NaN\n",
       "2  2020-02-26  Afghanistan          5.0                NaN\n",
       "3  2020-02-27  Afghanistan          5.0                NaN\n",
       "4  2020-02-28  Afghanistan          5.0                NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c535fbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                  object\n",
       "location              object\n",
       "total_cases          float64\n",
       "people_vaccinated    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ebf18",
   "metadata": {},
   "source": [
    "### 2. Process pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3cf51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e59d242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_relational_JH_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "    \n",
    "    data_url = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "    pd_raw = pd.read_csv(data_url, sep=\",\")\n",
    "    \n",
    "    pd_relational_model = pd_raw.loc[:, [\"date\", \"location\", \"total_cases\", \"people_vaccinated\"]]\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "    pd_relational_model=pd_relational_model.rename(columns={'total_cases':'confirmed',\n",
    "                      'location':'country'})\n",
    "\n",
    "    pd_relational_model.to_csv('/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/data/raw/COVID-19/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "    print(' Latest date is: '+str(max(pd_relational_model.date)))\n",
    "    print(pd_relational_model.head())\n",
    "    print(pd_relational_model.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e31da735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 202186\n",
      " Latest date is: 2022-07-18 00:00:00\n",
      "        date      country  confirmed  people_vaccinated\n",
      "0 2020-02-24  Afghanistan        5.0                NaN\n",
      "1 2020-02-25  Afghanistan        5.0                NaN\n",
      "2 2020-02-26  Afghanistan        5.0                NaN\n",
      "3 2020-02-27  Afghanistan        5.0                NaN\n",
      "4 2020-02-28  Afghanistan        5.0                NaN\n",
      "date                 datetime64[ns]\n",
      "country                      object\n",
      "confirmed                   float64\n",
      "people_vaccinated           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "store_relational_JH_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae80e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e9a1811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.1.1-cp38-cp38-macosx_10_13_x86_64.whl (8.5 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/pawnesh/ws/covid_data_science/covid_19_data_stats/venv/lib/python3.8/site-packages (from scikit-learn) (1.23.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.8.1-cp38-cp38-macosx_12_0_universal2.macosx_10_9_x86_64.whl (55.3 MB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.1.1 scipy-1.8.1 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e89b65",
   "metadata": {},
   "source": [
    "### 3 Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63e1e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "    try:\n",
    "        result=signal.savgol_filter(np.array(filter_in),\n",
    "                               window, # window size used for filtering\n",
    "                               1)\n",
    "    except (UnboundLocalError, ValueError) as e:\n",
    "        print(e)\n",
    "        result = filter_in\n",
    "    \n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "    \n",
    "    pd_filtered_result=df_output[['country',filter_on]].groupby(['country']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "    \n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "    \n",
    "\n",
    "    pd_DR_result= df_input.groupby(['country']).apply(rolling_reg,filter_on).reset_index()\n",
    "    #import pdb; pdb.set_trace()\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_1':'index'})\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b4fa2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test slope is: [2.]\n",
      "If mode is 'interp', window_length must be less than or equal to the size of x.\n"
     ]
    }
   ],
   "source": [
    "test_data_reg=np.array([2,4,6])\n",
    "result=get_doubling_time_via_regression(test_data_reg)\n",
    "print('the test slope is: '+str(result))\n",
    "\n",
    "pd_JH_data=pd.read_csv('/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/data/raw/COVID-19/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "pd_JH_data = pd_JH_data.reset_index()\n",
    "pd_JH_data=pd_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "#test_structure=pd_JH_data[((pd_JH_data['country']=='US')|\n",
    "#                  (pd_JH_data['country']=='Germany'))]\n",
    "\n",
    "pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "\n",
    "\n",
    "mask=pd_result_larg['confirmed']>100\n",
    "pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b92991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index_x       date  country   confirmed  people_vaccinated  \\\n",
      "69073    69073 2022-07-14  Germany  29569943.0         64717617.0   \n",
      "69074    69074 2022-07-15  Germany  29692989.0         64718873.0   \n",
      "69075    69075 2022-07-16  Germany  29692989.0         64719502.0   \n",
      "69076    69076 2022-07-17  Germany  29692989.0         64719652.0   \n",
      "69077    69077 2022-07-18  Germany  29853680.0         64720193.0   \n",
      "\n",
      "       confirmed_filtered  index_y  confirmed_DR  confirmed_filtered_DR  \n",
      "69073          29544854.0    69073    224.914146             249.481353  \n",
      "69074          29621831.8    69074    254.141047             329.136490  \n",
      "69075          29700518.0    69075    481.965666             380.594116  \n",
      "69076          29757265.4    69076           inf             438.490966  \n",
      "69077          29814012.8    69077    370.232965             524.381124  \n"
     ]
    }
   ],
   "source": [
    "pd_result_larg.to_csv('/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/data/raw/COVID-19/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "print(pd_result_larg[pd_result_larg['country']=='Germany'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0fb84",
   "metadata": {},
   "source": [
    "### 4 Visual Board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7afdac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/notebooks\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load src/visualization/visualize.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_input_large=pd.read_csv('/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/data/raw/COVID-19/processed/COVID_final_set.csv',sep=';')\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    #  Applied Data Science on COVID-19 data\n",
    "\n",
    "    Goal of the project is to teach data science by applying a cross industry standard process,\n",
    "    it covers the full walkthrough of: automated data gathering, data transformations,\n",
    "    filtering and machine learning to approximating the doubling time, and\n",
    "    (static) deployment of responsive dashboard.\n",
    "\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    ## Multi-Select Country for visualization\n",
    "    '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "        value=['United States', 'Germany','Italy'], # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "        ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "        {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "        {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "        {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "    ],\n",
    "    value='confirmed',\n",
    "    multi=False\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_window_slope')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['country']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis=my_yaxis\n",
    "        )\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212fb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
