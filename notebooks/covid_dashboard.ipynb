{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6193cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2951f2",
   "metadata": {},
   "source": [
    "### 1. update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06695a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "raw_data = pd.read_csv(data_url, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9cdfef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87261265",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = raw_data.loc[:, [\"date\", \"location\", \"total_cases\", \"people_vaccinated\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b16889",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ebf18",
   "metadata": {},
   "source": [
    "### 2. Process pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_relational_JH_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "    \n",
    "    data_url = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "    pd_raw = pd.read_csv(data_url, sep=\",\")\n",
    "    \n",
    "    pd_relational_model = pd_raw.loc[:, [\"date\", \"location\", \"total_cases\", \"people_vaccinated\"]]\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "    pd_relational_model=pd_relational_model.rename(columns={'total_cases':'confirmed',\n",
    "                      'location':'country'})\n",
    "\n",
    "    pd_relational_model.to_csv('/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/data/raw/COVID-19/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "    print(' Latest date is: '+str(max(pd_relational_model.date)))\n",
    "    print(pd_relational_model.head())\n",
    "    print(pd_relational_model.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31da735",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_relational_JH_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae80e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e89b65",
   "metadata": {},
   "source": [
    "### 3 Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e1e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "    try:\n",
    "        result=signal.savgol_filter(np.array(filter_in),\n",
    "                               window, # window size used for filtering\n",
    "                               1)\n",
    "    except (UnboundLocalError, ValueError) as e:\n",
    "        print(e)\n",
    "        result = filter_in\n",
    "    \n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "    \n",
    "    pd_filtered_result=df_output[['country',filter_on]].groupby(['country']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "    \n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "    \n",
    "\n",
    "    pd_DR_result= df_input.groupby(['country']).apply(rolling_reg,filter_on).reset_index()\n",
    "    #import pdb; pdb.set_trace()\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_1':'index'})\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4fa2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test slope is: [2.]\n",
      "If mode is 'interp', window_length must be less than or equal to the size of x.\n"
     ]
    }
   ],
   "source": [
    "test_data_reg=np.array([2,4,6])\n",
    "result=get_doubling_time_via_regression(test_data_reg)\n",
    "print('the test slope is: '+str(result))\n",
    "\n",
    "pd_JH_data=pd.read_csv('/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/data/raw/COVID-19/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "pd_JH_data = pd_JH_data.reset_index()\n",
    "pd_JH_data=pd_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "#test_structure=pd_JH_data[((pd_JH_data['country']=='US')|\n",
    "#                  (pd_JH_data['country']=='Germany'))]\n",
    "\n",
    "pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "\n",
    "\n",
    "mask=pd_result_larg['confirmed']>100\n",
    "pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b92991d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index_x       date  country   confirmed  people_vaccinated  \\\n",
      "69473    69473 2022-07-19  Germany  29994679.0         64721546.0   \n",
      "69474    69474 2022-07-20  Germany  30131303.0         64722459.0   \n",
      "69475    69475 2022-07-21  Germany  30239122.0         64723588.0   \n",
      "69476    69476 2022-07-22  Germany  30331131.0         64725416.0   \n",
      "69477    69477 2022-07-23  Germany  30331133.0                NaN   \n",
      "\n",
      "       confirmed_filtered  index_y  confirmed_DR  confirmed_filtered_DR  \n",
      "69473          29982354.6    69473    197.866127             303.523866  \n",
      "69474          30109983.0    69474    216.071584             253.222339  \n",
      "69475          30205473.6    69475    246.451740             269.804637  \n",
      "69476          30292747.2    69476    302.598755             330.510402  \n",
      "69477          30380020.8    69477    658.626947             347.100924  \n"
     ]
    }
   ],
   "source": [
    "pd_result_larg.to_csv('/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/data/raw/COVID-19/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "print(pd_result_larg[pd_result_larg['country']=='Germany'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0fb84",
   "metadata": {},
   "source": [
    "### 4 Visual Board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7afdac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/notebooks\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# %load src/visualization/visualize.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_input_large=pd.read_csv('/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/data/raw/COVID-19/processed/COVID_final_set.csv',sep=';')\n",
    "df_sir=pd.read_csv(\"/Users/pawnesh/ws/covid_data_science/covid_19_data_stats/data/processed/sir_data.csv\", sep=\";\")\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    #  Applied Data Science on COVID-19 data\n",
    "     Full walkthrough of: automated data gathering, data transformations,\n",
    "    filtering and machine learning to approximating the doubling time, and\n",
    "    (static) deployment of responsive dashboard.\n",
    "\n",
    "    '''),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    ## Multi-Select Country for visualization\n",
    "    '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "        value=['United States', 'Germany','Italy'], # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "\n",
    "    dcc.Markdown('''\n",
    "        ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        '''),\n",
    "\n",
    "\n",
    "    dcc.Dropdown(\n",
    "    id='doubling_time',\n",
    "    options=[\n",
    "        {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "        {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "        {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "        {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "        {'label': 'SIR Model', 'value': 'sir_value'},\n",
    "    ],\n",
    "    value='confirmed',\n",
    "    multi=False\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(figure=fig, id='main_window_slope')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    elif 'sir_value' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Population infection'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['country']==each]\n",
    "        \n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        elif show_doubling=='sir_value':\n",
    "            df_sir_filter = df_sir[[f\"{each}\", f\"{each}__infections\", f\"{each}__fitted\"]]\n",
    "            traces.append(dict(x=df_sir_filter[f\"{each}\"],\n",
    "                                y=df_sir_filter[f\"{each}__infections\"],\n",
    "                                mode='markers',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "            traces.append(dict(x=df_sir_filter[f\"{each}\"],\n",
    "                                y=df_sir_filter[f\"{each}__fitted\"],\n",
    "                                mode='lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "            \n",
    "        else:\n",
    "            df_plot=df_plot[['country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "            #print(show_doubling)\n",
    "\n",
    "\n",
    "            traces.append(dict(x=df_plot.date,\n",
    "                                    y=df_plot[show_doubling],\n",
    "                                    mode='markers+lines',\n",
    "                                    opacity=0.9,\n",
    "                                    name=each\n",
    "                            )\n",
    "                    )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis=my_yaxis\n",
    "        )\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212fb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93d25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b0392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e442e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
